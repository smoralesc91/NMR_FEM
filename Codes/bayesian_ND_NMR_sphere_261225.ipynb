{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960c79ea-38b2-4a91-a06e-8b0ed93e2713",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-26T18:33:51.348967Z",
     "iopub.status.busy": "2025-12-26T18:33:51.345032Z",
     "iopub.status.idle": "2025-12-26T18:33:58.052529Z",
     "shell.execute_reply": "2025-12-26T18:33:58.049916Z",
     "shell.execute_reply.started": "2025-12-26T18:33:51.348904Z"
    },
    "executionInfo": {
     "elapsed": 110490,
     "status": "ok",
     "timestamp": 1766767733989,
     "user": {
      "displayName": "Sinai Morales",
      "userId": "02882221959398016912"
     },
     "user_tz": 360
    },
    "id": "960c79ea-38b2-4a91-a06e-8b0ed93e2713",
    "outputId": "9f2df0fb-31e7-49f0-8627-80a038351d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is not Google Colab.\n",
      "Python version: 3.12.3\n",
      "numpy version: 1.26.4\n",
      "scipy version: 1.11.4\n",
      "matplotlib version: 3.6.3\n",
      "dolfin version: 2019.2.0.64.dev0\n",
      "gmsh version: 4.13.1\n",
      "mpmath version: 1.2.1\n",
      "ILT version: 1.0\n",
      "Functions_NMR version: 1.0\n",
      "FEM_NMR version: 1.5-spatial-profile\n",
      "SemiA_Sphere_NMR version: 1.7-spatial-profile\n",
      "Conv_NMR version: 1.0\n",
      "ND_FEM_NMR version: 0.4_Rigorous_Analytic\n",
      "SemiA_Sphere_NMR_dimensionless version: 1.1-dimless_flexible\n"
     ]
    }
   ],
   "source": [
    "import platform, sys, os, shutil\n",
    "import packaging.version as pv\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    print('Google Colab environment detected. Mounted Google Drive.')\n",
    "except ImportError:\n",
    "    print('This is not Google Colab.')\n",
    "\n",
    "python_version=platform.python_version()\n",
    "print('Python version:', python_version)\n",
    "\n",
    "if pv.parse(python_version) < pv.parse(\"3.0.0\"):\n",
    "    print(\"Python3 is needed!\")\n",
    "    print(\"How to fix: Runtime/Change_runtime_type/Python 3\")\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    from dolfin import *\n",
    "    from dolfin import __version__ as dolfin_version\n",
    "    import mshr\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import __version__ as mpl_version\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "    import scipy.optimize as opt\n",
    "    from scipy.stats import norm as sp_norm\n",
    "    from scipy.integrate import quad\n",
    "    from scipy.integrate import simpson\n",
    "    from scipy.signal import find_peaks\n",
    "    from scipy import __version__ as sp_version\n",
    "    from scipy.optimize import fsolve\n",
    "    import mpmath\n",
    "    import openturns as ot\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    from tabulate import tabulate\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.io as pio\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "    import csv\n",
    "    import json\n",
    "    import seaborn as sns\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "except ImportError as e:\n",
    "    !wget \"https://fem-on-colab.github.io/releases/fenics-install-release-real.sh\" -O \"/tmp/fenics-install.sh\" && bash \"/tmp/fenics-install.sh\"\n",
    "    from dolfin import *\n",
    "    from dolfin import __version__ as dolfin_version\n",
    "    import mshr\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import __version__ as mpl_version\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "    import scipy.optimize as opt\n",
    "    from scipy.stats import norm as sp_norm\n",
    "    from scipy.integrate import quad\n",
    "    from scipy.integrate import simpson\n",
    "    from scipy.signal import find_peaks\n",
    "    from scipy.optimize import fsolve\n",
    "    from scipy import __version__ as sp_version\n",
    "    import mpmath\n",
    "    !pip install openturns\n",
    "    import openturns as ot\n",
    "    !pip install scikit-learn\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import r2_score\n",
    "    from tabulate import tabulate\n",
    "    !pip install plotly\n",
    "    !pip install kaleido\n",
    "    import plotly.graph_objs as go\n",
    "    import plotly.io as pio\n",
    "    from datetime import datetime\n",
    "    import re\n",
    "    import csv\n",
    "    import json\n",
    "    import seaborn as sns\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "\n",
    "try:\n",
    "    import gmsh\n",
    "except ImportError:\n",
    "    !wget \"https://fem-on-colab.github.io/releases/gmsh-install.sh\" -O \"/tmp/gmsh-install.sh\" && bash \"/tmp/gmsh-install.sh\"\n",
    "    import gmsh\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.rc('ytick', labelsize=15)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('lines', linewidth=3)\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ot.Log.Show(ot.Log.NONE)\n",
    "\n",
    "set_log_level(30)\n",
    "set_log_level(LogLevel.ERROR)\n",
    "\n",
    "parameters['allow_extrapolation'] = True\n",
    "parameters[\"form_compiler\"][\"cpp_optimize\"] = True\n",
    "parameters[\"form_compiler\"][\"optimize\"] = True\n",
    "parameters[\"form_compiler\"][\"quadrature_degree\"] = 3\n",
    "parameters['form_compiler']['representation'] = 'uflacs'\n",
    "parameters['linear_algebra_backend'] = \"PETSc\"\n",
    "\n",
    "print('numpy version:', np.__version__)\n",
    "print('scipy version:', sp_version)\n",
    "print('matplotlib version:', mpl_version)\n",
    "print('dolfin version:', dolfin_version)\n",
    "print('gmsh version:', gmsh.__version__)\n",
    "print('mpmath version:', mpmath.__version__)\n",
    "\n",
    "try:\n",
    "    from ILT import *\n",
    "    from Functions_NMR import *\n",
    "    from FEM_NMR import *\n",
    "    from SemiA_Sphere_NMR import *\n",
    "    from Conv_NMR import *\n",
    "    from ND_FEM_NMR import *\n",
    "    from pytwalk import pytwalk\n",
    "    from SemiA_Sphere_NMR_dimensionless import *\n",
    "except ImportError:\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/ILT.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/Functions_NMR.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/FEM_NMR.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/SemiA_Sphere_NMR.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/Conv_NMR.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/ND_FEM_NMR.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/pytwalk.py'\n",
    "    !wget 'https://raw.githubusercontent.com/smoralesc91/NMR_FEM/main/Codes/SemiA_Sphere_NMR_dimensionless.py'\n",
    "\n",
    "    # Fix for ImportError: cannot import name 'mat' from 'numpy'\n",
    "    # This happens because 'mat' was deprecated and removed in NumPy 2.0.0+.\n",
    "    # We will patch the downloaded pytwalk.py file to replace 'mat' with 'asmatrix' in the import statement.\n",
    "    pytwalk_file_path = 'pytwalk.py'\n",
    "    if os.path.exists(pytwalk_file_path):\n",
    "        with open(pytwalk_file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Replace 'mat' with 'asmatrix' in the import line.\n",
    "        # This ensures the module can be imported successfully.\n",
    "        modified_content = content.replace(\n",
    "            'from numpy import ones, zeros, cumsum, shape, mat, cov, mean, ceil, matrix, sqrt',\n",
    "            'from numpy import ones, zeros, cumsum, shape, asmatrix, cov, mean, ceil, matrix, sqrt'\n",
    "        )\n",
    "\n",
    "        with open(pytwalk_file_path, 'w') as f:\n",
    "            f.write(modified_content)\n",
    "        print(\"Patched pytwalk.py to replace 'mat' with 'asmatrix' in import statement.\")\n",
    "    else:\n",
    "        print(f\"Warning: {pytwalk_file_path} not found for patching. pytwalk import might fail.\")\n",
    "\n",
    "    from ILT import *\n",
    "    from Functions_NMR import *\n",
    "    from FEM_NMR import *\n",
    "    from SemiA_Sphere_NMR import *\n",
    "    from Conv_NMR import *\n",
    "    from ND_FEM_NMR import *\n",
    "    from pytwalk import pytwalk # Try importing again after patching\n",
    "    from SemiA_Sphere_NMR_dimensionless import *\n",
    "\n",
    "print('ILT version:', ilt.__version__)\n",
    "print('Functions_NMR version:', NMR_Functions.__version__)\n",
    "print('FEM_NMR version:', NMR_FEM.__version__)\n",
    "print('SemiA_Sphere_NMR version:', NMR_SemiA_sphere.__version__)\n",
    "print('Conv_NMR version:', NMR_Conventional.__version__)\n",
    "print('ND_FEM_NMR version:', ND_BT_FEM.__version__)\n",
    "print('SemiA_Sphere_NMR_dimensionless version:', NMR_SemiA_sphere_dimless.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SgAdzZZXPSxS",
   "metadata": {
    "id": "SgAdzZZXPSxS"
   },
   "source": [
    "# Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V_GfYzIKew7a",
   "metadata": {
    "id": "V_GfYzIKew7a"
   },
   "source": [
    "Six case studies were conducted, varying the surface relaxivity and pore radius. Parameters such as diffusion, T2 bulk, and others, as shown in the following table, were kept constant.\n",
    "\n",
    "\n",
    "| Parameter | Symbol (Units) | Case 1 | Case 2 | Case 3 | Case 4 | Case 5 | Case 6 |\n",
    "| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| Radius | $r$ ($m$) | $2.25 \\times 10^{-6}$ | $100 \\times 10^{-6}$ | $2.25 \\times 10^{-6}$ | $100 \\times 10^{-6}$ | $2.25 \\times 10^{-6}$ | $100 \\times 10^{-6}$ |\n",
    "| Surface Relaxivity | $\\rho$ ($m/s$) | $1.00 \\times 10^{-6}$ | $1.00 \\times 10^{-6}$ | $40 \\times 10^{-6}$ | $40 \\times 10^{-6}$ | $20 \\times 10^{-6}$ | $20 \\times 10^{-6}$ |\n",
    "| Diffusion Coeff. | $D_0$ ($m^2/s$) | $2.30 \\times 10^{-9}$ | $2.30 \\times 10^{-9}$ | $2.30 \\times 10^{-9}$ | $2.30 \\times 10^{-9}$ | $2.30 \\times 10^{-9}$ | $2.30 \\times 10^{-9}$ |\n",
    "| Bulk Relaxation | $T_{2B}$ ($s$) | $2.00$ | $2.00$ | $2.00$ | $2.00$ | $2.00$ | $2.00$ |\n",
    "| Start Time | $t_0$ ($s$) | $0.00$ | $0.00$ | $0.00$ | $0.00$ | $0.00$ | $0.00$ |\n",
    "| Final Time | $t_f$ ($s$) | $10.00$ | $10.00$ | $10.00$ | $10.00$ | $10.00$ | $10.00$ |\n",
    "| Time Step | $\\Delta t$ ($s$) | $0.01$ | $0.01$ | $0.01$ | $0.01$ | $0.01$ | $0.01$ |\n",
    "| Burn-in | - | $300$ | $300$ | $300$ | $300$ | $300$ | $300$ |\n",
    "| SNR | - | $50$ | $50$ | $50$ | $50$ | $50$ | $50$ |\n",
    "| Mesh Resolution | - | $60$ | $60$ | $60$ | $60$ | $60$ | $60$ |\n",
    "| Iterations | - | $1000$ | $1000$ | $1000$ | $1000$ | $1000$ | $1000$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4a914f-f954-4f6b-bc02-ed58d79335f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T18:34:03.826271Z",
     "iopub.status.busy": "2025-12-26T18:34:03.825632Z",
     "iopub.status.idle": "2025-12-26T18:34:03.913498Z",
     "shell.execute_reply": "2025-12-26T18:34:03.912153Z",
     "shell.execute_reply.started": "2025-12-26T18:34:03.826221Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. GLOBAL CONFIGURATION\n",
    "# ==========================================\n",
    "D_REF   = 2.3e-9      # [m^2/s] Self-diffusion coefficient (water)\n",
    "T2B_REF = 2.0         # [s] Bulk relaxation time\n",
    "SNR     = 50.0        # Signal-to-Noise Ratio\n",
    "SIGMA_TRUE = 1.0 / SNR\n",
    "DT_VALUE = 1.e-2      # [s] Temporal discretization\n",
    "TWALK_ITERATIONS = 700 # Number of iterations for pytwalk\n",
    "BURN_IN_PERIOD = 300   # Number of samples to discard as burn-in\n",
    "\n",
    "# List of Requested Cases\n",
    "CASES = [\n",
    "    #{\"id\": \"Case1\", \"R\": 2.25e-6,   \"rho\": 1.0e-6,  \"tf\": 10.0}, # Small Pore, Slow Relax.\n",
    "    {\"id\": \"Case2\", \"R\": 100e-6, \"rho\": 1.0e-6,  \"tf\": 5.0}, # Large Pore, Slow Relax.\n",
    "    #{\"id\": \"Case3\", \"R\": 2.25e-6,   \"rho\": 40.0e-6, \"tf\": 10.0}, # Small Pore, Fast Relax.\n",
    "    #{\"id\": \"Case4\", \"R\": 100e-6, \"rho\": 40.0e-6, \"tf\": 10.0}, # Large Pore, Fast Relax.\n",
    "    #{\"id\": \"Case5\", \"R\": 2.25e-6,   \"rho\": 20.0e-6, \"tf\": 10.0}, # Small Pore, Medium Relax.\n",
    "    #{\"id\": \"Case6\", \"R\": 100e-6, \"rho\": 20.0e-6, \"tf\": 10.0}  # Large Pore, Medium Relax.\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = \"Bayesian_FEM_Results\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. CORE FUNCTION (RUNS A SINGLE CASE)\n",
    "# ==========================================\n",
    "def run_single_case(case_params):\n",
    "    start_total_time = time.time() # Start total time measurement\n",
    "\n",
    "    case_id = case_params[\"id\"]\n",
    "    R_true  = case_params[\"R\"]\n",
    "    rho_true = case_params[\"rho\"]\n",
    "    tf_val   = case_params[\"tf\"]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" PROCESSING {case_id}: R={R_true*1e6:.2f}um, rho={rho_true*1e6:.1f}um/s\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # --- A. Generate Synthetic Data (Ground Truth) ---\n",
    "    print(\"-> Generating synthetic data (FEM High-Res)...\")\n",
    "    t_gen, s_gen = ND_BT_FEM(\n",
    "        radius=R_true, diffusion=D_REF, rho=rho_true, T2B=T2B_REF,\n",
    "        t_0=0.0, t_f=tf_val, dt=DT_VALUE, \n",
    "        mesh_res=300,\n",
    "        volume_=False, normalize=True, return_data='time-mag',\n",
    "        linear_solver='mumps'\n",
    "    )\n",
    "\n",
    "    # Add Gaussian Noise\n",
    "    rng = np.random.default_rng(42)\n",
    "    y_obs = s_gen + rng.normal(0, SIGMA_TRUE, size=s_gen.shape)\n",
    "    t_obs = t_gen\n",
    "\n",
    "    # --- B. Define Inverse Model (Closure) ---\n",
    "    def forward_fem_mcmc(alpha_cand):\n",
    "        rho_cand = alpha_cand * np.sqrt(D_REF / T2B_REF)\n",
    "        try:\n",
    "            _, s_out = ND_BT_FEM(\n",
    "                radius=R_true, diffusion=D_REF, rho=rho_cand, T2B=T2B_REF,\n",
    "                t_0=0.0, t_f=tf_val, dt=DT_VALUE,\n",
    "                mesh_res=60, # Optimization for speed\n",
    "                volume_=False, normalize=True, return_data='time-mag',\n",
    "                progress=False, linear_solver='mumps'\n",
    "            )\n",
    "            return s_out\n",
    "        except:\n",
    "            return np.full_like(t_obs, -10.0)\n",
    "\n",
    "    def Supp(x):\n",
    "        if not (1e-4 < x[0] < 20.0): return False \n",
    "        if not (1e-5 < x[1] < 0.2):  return False \n",
    "        return True\n",
    "\n",
    "    def Energy(x):\n",
    "        if not Supp(x): return np.inf\n",
    "        alpha_val, sigma_val = x\n",
    "        s_pred = forward_fem_mcmc(alpha_val)\n",
    "        if np.any(s_pred == -10.0): return np.inf\n",
    "        resid = y_obs - s_pred\n",
    "        n = len(y_obs)\n",
    "        log_lik = -n * np.log(sigma_val) - 0.5 * np.sum(resid**2) / sigma_val**2\n",
    "        return -log_lik\n",
    "\n",
    "    # --- C. Execute pytwalk (MCMC) ---\n",
    "    print(\"-> Starting MCMC...\")\n",
    "    x0  = np.array([0.1, 0.05])\n",
    "    xp0 = np.array([1.0, 0.01])\n",
    "    tw = pytwalk(n=2, U=Energy, Supp=Supp)\n",
    "\n",
    "    start_mcmc_time = time.time()\n",
    "    tw.Run(T=TWALK_ITERATIONS, x0=x0, xp0=xp0)\n",
    "    elapsed_mcmc = time.time() - start_mcmc_time\n",
    "    print(f\"-> MCMC finished in {elapsed_mcmc:.2f} s\")\n",
    "\n",
    "    # --- D. Analysis ---\n",
    "    burn = BURN_IN_PERIOD\n",
    "    chain = tw.Output\n",
    "    alpha_post = chain[burn:, 0]\n",
    "    sigma_post = chain[burn:, 1]\n",
    "    U_post     = chain[burn:, -1]\n",
    "\n",
    "    # 1. MAP Estimator\n",
    "    idx_map = np.argmin(U_post)\n",
    "    alpha_map = alpha_post[idx_map]\n",
    "    sigma_map = sigma_post[idx_map]\n",
    "    rho_map = alpha_map * np.sqrt(D_REF / T2B_REF)\n",
    "    \n",
    "    # 2. Statistics on Posterior\n",
    "    rho_post_phys = alpha_post * np.sqrt(D_REF/T2B_REF)\n",
    "    rho_mean = float(np.mean(rho_post_phys))\n",
    "    rho_median = float(np.median(rho_post_phys))\n",
    "    rho_std = float(np.std(rho_post_phys))\n",
    "    rho_var = float(np.var(rho_post_phys))\n",
    "    \n",
    "    # --- E. ERROR CALCULATION (Comprehensive) ---\n",
    "    \n",
    "    # Helper for repetitive calc\n",
    "    def get_errors(estimate, truth):\n",
    "        abs_err = abs(estimate - truth)\n",
    "        pct_err = (abs_err / truth) * 100.0\n",
    "        return abs_err, pct_err\n",
    "\n",
    "    # MAP Errors\n",
    "    rho_err_abs_map, rho_err_pct_map = get_errors(rho_map, rho_true)\n",
    "    \n",
    "    # MEAN Errors\n",
    "    rho_err_abs_mean, rho_err_pct_mean = get_errors(rho_mean, rho_true)\n",
    "    \n",
    "    # MEDIAN Errors\n",
    "    rho_err_abs_med, rho_err_pct_med = get_errors(rho_median, rho_true)\n",
    "\n",
    "    # Generate MAP prediction for signal metrics\n",
    "    s_map = forward_fem_mcmc(alpha_map)\n",
    "    metrics = compute_error_metrics(y_true=s_gen, y_pred=s_map, t=t_obs)\n",
    "\n",
    "    total_elapsed_time = time.time() - start_total_time \n",
    "\n",
    "    # --- F. Save Results (JSON Structured) ---\n",
    "    case_dir = os.path.join(OUTPUT_DIR, case_id)\n",
    "    os.makedirs(case_dir, exist_ok=True)\n",
    "\n",
    "    report = {\n",
    "        \"case_id\": case_id,\n",
    "        \"inputs\": {\"R\": R_true, \"rho_true\": rho_true, \"tf\": tf_val, \"SNR\": SNR, \"dt\": DT_VALUE, \"twalk_iterations\": TWALK_ITERATIONS, \"burn_in_period\": BURN_IN_PERIOD},\n",
    "        \n",
    "        # Section 1: MAP (Mode)\n",
    "        \"recovered_map\": {\n",
    "            \"rho\": rho_map,\n",
    "            \"rho_error_abs\": rho_err_abs_map,\n",
    "            \"rho_error_percent\": rho_err_pct_map,\n",
    "            \"alpha\": alpha_map,\n",
    "            \"sigma\": sigma_map\n",
    "        },\n",
    "        \n",
    "        # Section 2: Mean (Expected Value)\n",
    "        \"recovered_mean\": {\n",
    "            \"rho\": rho_mean,\n",
    "            \"rho_error_abs\": rho_err_abs_mean,\n",
    "            \"rho_error_percent\": rho_err_pct_mean\n",
    "        },\n",
    "        \n",
    "        # Section 3: Median (Robust Central Tendency)\n",
    "        \"recovered_median\": {\n",
    "            \"rho\": rho_median,\n",
    "            \"rho_error_abs\": rho_err_abs_med,\n",
    "            \"rho_error_percent\": rho_err_pct_med\n",
    "        },\n",
    "        \n",
    "        # Section 4: Dispersion / Uncertainty\n",
    "        \"posterior_stats\": {\n",
    "            \"rho_std\": rho_std,\n",
    "            \"rho_var\": rho_var\n",
    "        },\n",
    "        \n",
    "        \"signal_errors\": metrics,\n",
    "        \"mcmc_time_s\": elapsed_mcmc,\n",
    "        \"total_simulation_time_s\": total_elapsed_time\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(case_dir, \"metrics.json\"), 'w') as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    # CSV Chain\n",
    "    np.savetxt(os.path.join(case_dir, \"chain.csv\"), chain[::1, :],\n",
    "               header=\"alpha,sigma,energy,log_posterior\", delimiter=\",\")\n",
    "\n",
    "    # --- G. Plotting ---\n",
    "    fig = plt.figure(figsize=(15, 10)) \n",
    "    gs = GridSpec(2, 2, figure=fig) \n",
    "\n",
    "    # 1. Traceplot\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.plot(rho_post_phys, alpha=1, lw=1)\n",
    "    ax0.axhline(rho_true, color='r', ls='--', label='True')\n",
    "    ax0.set_title(f\"{case_id}: Rho Traceplot\")\n",
    "    ax0.set_ylabel(\"Rho [m/s]\")\n",
    "    ax0.set_xlabel(\"Iteration\")\n",
    "    ax0.legend()\n",
    "\n",
    "    # 2. Signal Fit\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    ax1.plot(t_obs, y_obs, 'k.', alpha=0.1, label='Noisy Data')\n",
    "    ax1.plot(t_obs, s_map, 'r-', lw=2, label='MAP Model')\n",
    "    ax1.set_title(f\"Fit (Global Err={metrics['Global_Rel_Error_Pct']:.3f}%)\")\n",
    "    ax1.legend()\n",
    "    ax1.set_xlabel(\"Time [s]\")\n",
    "    ax1.set_ylabel(\"Normalized Signal\")\n",
    "\n",
    "    # 3. Posterior Distribution (Updated with Median)\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    sns.histplot(rho_post_phys, bins=25, kde=True, color='skyblue', alpha=0.7, ax=ax2, stat='density')\n",
    "    ax2.axvline(rho_true, color='r', ls='--', lw=2, label='True')\n",
    "    ax2.axvline(rho_map, color='k', ls='-', label=f'MAP')\n",
    "    ax2.axvline(rho_median, color='g', ls=':', lw=2, label=f'Median') # Added Median line\n",
    "    ax2.set_title(\"Rho Posterior Distribution\")\n",
    "    ax2.legend()\n",
    "    ax2.set_xlabel(\"Rho [m/s]\")\n",
    "    ax2.set_ylabel(\"Density\")\n",
    "\n",
    "    # Inset boxplot\n",
    "    box_ax_posterior = ax2.inset_axes([0, 1.05, 1, 0.15], transform=ax2.transAxes)\n",
    "    sns.boxplot(x=rho_post_phys, ax=box_ax_posterior, color='skyblue', orient='h', width=0.8, linewidth=1, fliersize=2)\n",
    "    box_ax_posterior.axis('off')\n",
    "\n",
    "    # 4. Prior Distribution\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    alpha_prior_samples = rng.uniform(1e-4, 20.0, 10000)\n",
    "    rho_prior_samples = alpha_prior_samples * np.sqrt(D_REF / T2B_REF)\n",
    "    sns.histplot(rho_prior_samples, bins=50, kde=True, color='lightgreen', alpha=0.7, ax=ax3, stat='density')\n",
    "    ax3.axvline(rho_true, color='r', ls='--', lw=2, label='True')\n",
    "    ax3.set_title(\"Rho Prior Distribution\")\n",
    "    ax3.legend()\n",
    "    ax3.set_xlabel(\"Rho [m/s]\")\n",
    "    \n",
    "    # Inset boxplot\n",
    "    box_ax_prior = ax3.inset_axes([0, 1.05, 1, 0.15], transform=ax3.transAxes)\n",
    "    sns.boxplot(x=rho_prior_samples, ax=box_ax_prior, color='lightgreen', orient='h', width=0.8, linewidth=1, fliersize=2)\n",
    "    box_ax_prior.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(case_dir, \"plot_dashboard_enhanced.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"-> Results saved in {case_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5bba25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-26T18:34:06.126180Z",
     "iopub.status.busy": "2025-12-26T18:34:06.125663Z",
     "iopub.status.idle": "2025-12-26T18:45:39.609020Z",
     "shell.execute_reply": "2025-12-26T18:45:39.607903Z",
     "shell.execute_reply.started": "2025-12-26T18:34:06.126146Z"
    },
    "executionInfo": {
     "elapsed": 1229484,
     "status": "ok",
     "timestamp": 1766077523864,
     "user": {
      "displayName": "Sinai Morales",
      "userId": "02882221959398016912"
     },
     "user_tz": 360
    },
    "id": "7c5bba25",
    "outputId": "8dbcf725-0d00-414e-b7f4-90ba1c6ede02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Simulation (FEM)...\n",
      "\n",
      "============================================================\n",
      " PROCESSING Case2: R=100.00um, rho=1.0um/s\n",
      "============================================================\n",
      "-> Generating synthetic data (FEM High-Res)...\n",
      "-> Starting MCMC (this may take a few minutes)...\n",
      "pytwalk: Running the twalk with 700 iterations .  Fri, 26 Dec 2025, 12:34:07.\n",
      "       Finish by Fri, 26 Dec 2025, 12:48.\n",
      "pytwalk:         64 iterations so far. Finish by Fri, 26 Dec 2025, 12:41.\n",
      "pytwalk:        256 iterations so far. Finish by Fri, 26 Dec 2025, 12:43.\n",
      "pytwalk:        384 iterations so far. Finish in approx. 4 min and 50 sec.\n",
      "pytwalk: finished, Fri, 26 Dec 2025, 12:45:36.\n",
      "-> MCMC finished in 688.96 s\n",
      "-> Results saved in Bayesian_FEM_Results/Case2\n",
      "\n",
      "\n",
      "=== ALL CASES FINISHED ===\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. MAIN EXECUTION\n",
    "# ==========================================\n",
    "print(\"Starting Bayesian Simulation (FEM)...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "for case in CASES:\n",
    "    run_single_case(case)\n",
    "\n",
    "print(\"\\n\\n=== ALL CASES FINISHED ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c363e9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1766077654005,
     "user": {
      "displayName": "Sinai Morales",
      "userId": "02882221959398016912"
     },
     "user_tz": 360
    },
    "id": "7c363e9c",
    "outputId": "b74851fa-67c1-429d-efd4-8e352742b034"
   },
   "outputs": [],
   "source": [
    "# Data collection\n",
    "cases_data = []\n",
    "for case_info in CASES:\n",
    "    case_id = case_info[\"id\"]\n",
    "    case_dir = os.path.join(OUTPUT_DIR, case_id)\n",
    "    metrics_path = os.path.join(case_dir, \"metrics.json\")\n",
    "\n",
    "    if os.path.exists(metrics_path):\n",
    "        with open(metrics_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        cases_data.append({\n",
    "            \"case_id\": case_id,\n",
    "            \"rho_true\": metrics[\"inputs\"][\"rho_true\"],\n",
    "            \"rho_map\": metrics[\"recovered_map\"][\"rho\"]\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Warning: {metrics_path} not found.\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "case_ids = [d[\"case_id\"] for d in cases_data]\n",
    "rho_true_values = [d[\"rho_true\"] for d in cases_data]\n",
    "rho_map_values = [d[\"rho_map\"] for d in cases_data]\n",
    "\n",
    "x = np.arange(len(case_ids))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width/2, rho_true_values, width, label='True Rho')\n",
    "rects2 = ax.bar(x + width/2, rho_map_values, width, label='Estimated Rho (MAP)')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Rho [m/s]')\n",
    "ax.set_title('Comparison of True vs. Estimated Rho across Cases')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(case_ids)\n",
    "ax.legend()\n",
    "ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0)) # Scientific notation for y-axis\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf6cdb",
   "metadata": {
    "id": "ddcf6cdb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
